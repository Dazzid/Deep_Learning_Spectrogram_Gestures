# Deep_Learning_Spectrogram_Gestures

Detecting patterns from Mel-Spectrograms extracted from gestural excercices perfomed by expert violinists. 

We used: 
- Python '3.6.8' 
- TensorFlow '2.0.0' 
- NumPy '1.17.4' 
- Scikit-learn '0.23.1' 
- Pyquaternion '0.9.5'.

## Music Score
8 Gestures were recorded by professional violinist and students in the Royal College of Music in London.

<img src="https://github.com/Dazzid/Applying_Deep_Learning_Techniques_to_Estimate_Patterns_of_Musical_Gesture/blob/master/figures/01_music_score_eight_gestures.jpg" width=80%/>

## Spectrogram Shapes
<img src="https://github.com/Dazzid/Deep_Learning_Spectrogram_Gestures/blob/master/figures/complete_spectrogram_gestures.png" width=80%/>

## Licence
The code is released under the [Apache License, Version 2.0](https://github.com/tensorflow/tensorflow/blob/master/LICENSE)
The IMU sensor samples are released under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA 4.0) [license](http://creativecommons.org/licenses/by-nc-sa/4.0/).
